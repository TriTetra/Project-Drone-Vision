import os 
import argparse
import random
import shutil
from pathlib import Path
from collections import defaultdict
import textwrap
from tqdm import tqdm   


SPLIT_RATIOS = {
    'train': 0.7,
    'val': 0.2,
    'test': 0.1
}

RANDOM_SEED = 42    

def prepare_dataset(source_dir, output_dir, split_ratios=SPLIT_RATIOS, seed=RANDOM_SEED):
    random.seed(seed)

    if not os.path.exists(source_dir):
        raise FileNotFoundError(f"The source directory {source_dir} does not exist.")

    print(f"Preparing dataset from {source_dir} into {output_dir} with seed {seed}...")

    # 1. Scan for all image files
    valid_extensions = ('.jpg', 'jpeg', '.png', '.JPG', '.JPEG', '.PNG', '.bmp', '.BMP', '.tiff', '.TIFF')
    all_images = []

    images = []
    for file in os.listdir(source_dir):
        if file.lower().endswith(valid_extensions):
            images.append(file)

    
    for image in images:
        base_name = os.path.splitext(image)[0]
        label_file = base_name + ".txt"
        label_path = os.path.join(source_dir, label_file)

        if os.path.exists(label_path):
            all_images.append({
                'image': image,
                'label': label_file,
                'base_name': base_name
            })

    if len(all_images) == 0:
        raise ValueError(f"No valid image-label pairs found in {source_dir}.")
    
    # 2. Shuffle and split the dataset
    random.shuffle(all_images)

    # 3. Calculate split indices
    total_count = len(all_images)
    train_end = int(total_count * split_ratios['train'])
    val_end = train_end + int(total_count * split_ratios['val'])

    splits = {
        'train': all_images[:train_end],
        'val': all_images[train_end:val_end],
        'test': all_images[val_end:]
    }
        
    # 4. Create output directories and copy files
    class_stats = defaultdict(int)

    for split, items in splits.items():
        split_image_dir = os.path.join(output_dir, split, 'images')
        split_label_dir = os.path.join(output_dir, split, 'labels')
        os.makedirs(split_image_dir, exist_ok=True)
        os.makedirs(split_label_dir, exist_ok=True)

        for item in tqdm(items, desc=f"{split} process"):
            shutil.copy2(os.path.join(source_dir, item['image']), os.path.join(split_image_dir, item['image']))
            shutil.copy2(os.path.join(source_dir, item['label']), os.path.join(split_label_dir, item['label']))

            try:
                with open(os.path.join(source_dir, item['label']), 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if parts:
                            class_id = parts[0]
                            class_stats[class_id] += 1
            except Exception as e:
                print(f"Error reading label file {item['label']}: {e}")


    # 5. data.yaml generation
    yaml_content = textwrap.dedent(f"""
        # YOLO Dataset Configuration
        # Generated by prepare_dataset.py
        # Seed: {RANDOM_SEED}

        path: {os.path.abspath(output_dir)}
        train: train/images
        val: val/images
        test: test/images

        names: 
          0: red_square
          1: blue_square

        nc: 2
        """)
    
    yaml_path = os.path.join(output_dir, 'data.yaml')

    with open(yaml_path, 'w') as f:
        f.write(yaml_content)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Prepare dataset by splitting into train, val, and test sets.")
    parser.add_argument("--source_dir", type=str, help="Path to the source directory containing images and labels.")
    parser.add_argument("--output_dir", type=str, help="Path to the output directory for the prepared dataset.")
    
    args = parser.parse_args()
    prepare_dataset(args.source, args.dest)
